# ロードマップ

## フェーズ概要

```
Phase 1: MVP        Phase 2: 拡張      Phase 3: 統合      Phase 4: 高度化
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
基本パイプライン  →  データ拡充     →  IDE/LLM連携   →  高度な最適化
Git取り込み          ドキュメント連携    プラグイン開発     知識転移
QLoRA学習           合成データ生成      継続学習           カスタムアーキ
Ollama出力          評価システム        マルチプロジェクト  エッジ最適化
```

---

## Phase 1: MVP（基本パイプライン）

### 目標
最小限の機能でエンドツーエンドの動作を確認

### 成果物
- [ ] CLIツール基本構造
- [ ] Gitリポジトリからのコード取り込み
- [ ] 基本的なコードチャンク化
- [ ] QLoRAによるファインチューニング
- [ ] Ollama形式でのモデルエクスポート

### タスク詳細

#### 1.1 プロジェクト基盤
```
- [ ] Python パッケージ構成 (pyproject.toml)
- [ ] CLI フレームワーク (Click/Typer)
- [ ] 設定ファイル形式の決定 (YAML/TOML)
- [ ] ロギング基盤
- [ ] 基本的なテスト構成
```

#### 1.2 データ取り込み
```
- [ ] Git リポジトリのクローン/読み込み
- [ ] ファイル一覧の取得とフィルタリング
- [ ] 言語検出 (linguist/guesslang)
- [ ] 基本的なコードパース（Python優先）
```

#### 1.3 前処理
```
- [ ] 関数単位でのコード分割
- [ ] トークナイズと長さ制限
- [ ] 学習データフォーマット変換 (Alpaca形式)
- [ ] Train/Eval分割
```

#### 1.4 学習
```
- [ ] Hugging Face Transformers セットアップ
- [ ] QLoRA 設定
- [ ] 基本的な学習ループ
- [ ] チェックポイント保存
```

#### 1.5 エクスポート
```
- [ ] LoRAアダプタのマージ
- [ ] GGUF変換 (llama.cpp)
- [ ] Ollama Modelfile生成
- [ ] 動作確認スクリプト
```

### CLI インターフェース（MVP）

```bash
# リポジトリから学習
mochi train \
  --repo ./my-project \
  --base-model Qwen/Qwen2.5-Coder-1.5B \
  --output ./output

# モデルをOllamaにインストール
mochi export --format ollama --model ./output

# テスト推論
mochi test --model ./output --prompt "def hello():"
```

---

## Phase 2: データ拡充

### 目標
学習データの質と量を向上させ、より高品質なSLMを生成

### 成果物
- [ ] ドキュメント・Markdown対応
- [ ] Issue/PR連携（GitHub API）
- [ ] LLMによる合成データ生成
- [ ] 重複排除パイプライン
- [ ] 評価メトリクス基盤

### タスク詳細

#### 2.1 追加データソース
```
- [ ] Markdown/RST パーサー
- [ ] GitHub Issues/PR取得
- [ ] コミット履歴解析
- [ ] コードコメント抽出
```

#### 2.2 データ品質向上
```
- [ ] MinHashLSH による重複排除
- [ ] 構文エラーチェック
- [ ] 機密情報スキャン (secrets detection)
- [ ] データバランシング
```

#### 2.3 合成データ
```
- [ ] LLM API連携 (Claude/OpenAI)
- [ ] Q&Aペア自動生成
- [ ] コード説明生成
- [ ] バリエーション生成
```

#### 2.4 評価システム
```
- [ ] Perplexity計測
- [ ] CodeBLEUスコア
- [ ] 構文正当性チェック
- [ ] プロジェクト固有ベンチマーク生成
```

---

## Phase 3: 統合・運用

### 目標
実際の開発ワークフローへの統合

### 成果物
- [ ] VSCode拡張機能
- [ ] Claude Code MCP連携
- [ ] 継続学習パイプライン
- [ ] マルチプロジェクト対応
- [ ] Web UI（オプション）

### タスク詳細

#### 3.1 IDE統合
```
- [ ] VSCode Extension基盤
- [ ] インライン補完UI
- [ ] コンテキスト送信機能
- [ ] 設定パネル
```

#### 3.2 LLM連携
```
- [ ] MCP Server実装
- [ ] プロンプト強化パイプライン
- [ ] コンテキスト圧縮
- [ ] フォールバック処理
```

#### 3.3 継続学習
```
- [ ] 差分検出 (git hooks)
- [ ] 増分学習パイプライン
- [ ] アダプタバージョン管理
- [ ] 自動再学習トリガー
```

#### 3.4 マルチプロジェクト
```
- [ ] プロジェクト設定管理
- [ ] モデルレジストリ
- [ ] 共有/プライベート設定
```

---

## Phase 4: 高度化

### 目標
性能・効率のさらなる向上と高度な機能

### 成果物
- [ ] プロジェクト間知識転移
- [ ] カスタムモデルアーキテクチャ
- [ ] エッジデバイス最適化
- [ ] 分散学習対応

### タスク詳細

#### 4.1 知識転移
```
- [ ] ドメイン類似度計算
- [ ] 転移学習パイプライン
- [ ] 共通知識の抽出・再利用
```

#### 4.2 アーキテクチャ探索
```
- [ ] プルーニング/蒸留
- [ ] アーキテクチャサーチ
- [ ] タスク特化層の追加
```

#### 4.3 エッジ最適化
```
- [ ] 極小量子化 (2bit/3bit)
- [ ] モバイル向け最適化
- [ ] WebAssembly対応
```

---

## マイルストーン

| マイルストーン | 成果物 | 検証基準 |
|---------------|--------|----------|
| M1: 動作確認 | MVP CLI | 単一リポジトリで学習→推論が動作 |
| M2: 品質確認 | 評価システム | ベースラインより性能向上を確認 |
| M3: 統合確認 | IDE連携 | VSCodeで補完が利用可能 |
| M4: 運用確認 | 継続学習 | 新コミット反映が自動化 |

---

## リスクと対策

| リスク | 影響 | 対策 |
|--------|------|------|
| 学習データ不足 | 品質低下 | 合成データ生成、類似OSSの活用 |
| 計算リソース | コスト増 | クラウドスポットインスタンス活用 |
| モデル劣化 | 性能低下 | 定期評価、ロールバック機能 |
| ライセンス問題 | 法的リスク | ライセンススキャン自動化 |

---

## 技術的負債の管理

各フェーズで以下を実施:
- [ ] コードレビュー
- [ ] テストカバレッジ維持（80%以上）
- [ ] ドキュメント更新
- [ ] 依存関係の監査
