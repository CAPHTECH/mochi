# Mochi - ドメイン特化型SLM生成システム

プロジェクト固有の知識を学習した軽量SLM（Small Language Model）を生成し、LLMによるコード生成の精度を向上させるシステム。

## 概要

```
┌─────────────────────────────────────────────────────────────┐
│                         Mochi                                │
├─────────────────────────────────────────────────────────────┤
│  [プロジェクト資産]     [学習パイプライン]     [SLM出力]      │
│                                                              │
│   ソースコード ──┐                                           │
│   ドキュメント ──┼──▶ 前処理 ──▶ 学習 ──▶ ドメイン特化SLM    │
│   コミット履歴 ──┤         ▲                    │            │
│   Issue/PR ─────┘         │                    ▼            │
│                      ベースSLM            LLM補助として      │
│                    (Phi-3, Gemma等)        デプロイ          │
└─────────────────────────────────────────────────────────────┘
```

## 解決する課題

| 課題 | Mochiによる解決 |
|------|-----------------|
| LLMはプロジェクト固有の規約・パターンを知らない | プロジェクト知識を埋め込んだSLMが補完 |
| RAGだけでは文脈理解が浅い | 学習により深い理解を実現 |
| 毎回の大量コンテキスト送信はコスト高 | SLMがローカルで高速に補助 |
| 機密コードをクラウドに送りたくない | オンプレミス/ローカル実行可能 |

## 主要機能

1. **データ取り込み** - Git、ドキュメント、Issue/PRからの自動収集
2. **前処理パイプライン** - コードのチャンク化、正規化、重複排除
3. **学習データ生成** - コード補完ペア、Q&Aデータセットの自動生成
4. **ファインチューニング** - QLoRA/LoRAによる効率的な学習
5. **デプロイ** - Ollama/GGUF形式でのエクスポート

## ドキュメント

- [アーキテクチャ設計](./architecture.md)
- [データパイプライン](./data-pipeline.md)
- [学習戦略](./training-strategy.md)
- [ロードマップ](./roadmap.md)

## クイックスタート

```bash
# インストール（予定）
pip install mochi-slm

# プロジェクトからSLMを生成
mochi train --repo ./your-project --output ./model

# 生成したSLMを利用
mochi serve --model ./model
```

## 技術スタック

- **ベースモデル**: Phi-3-mini, Qwen2.5-Coder, CodeGemma
- **学習フレームワーク**: Hugging Face Transformers + PEFT/Unsloth
- **推論エンジン**: llama.cpp / Ollama
- **言語**: Python 3.11+

## ライセンス

MIT License
